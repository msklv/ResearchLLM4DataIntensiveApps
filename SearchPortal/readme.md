# Корпоративный портал для поиска информации

## Технологии

- Ollama ([Сбер для теста](https://foundation-models.api.cloud.ru/v1))
- open-webui
- [Qdrant](https://qdrant.tech/)
- Docker

## Быстрый старт (docker-compose)

Для локального тестирования стека (Ollama + Qdrant + Open WebUI) используйте `docker-compose` ниже.

### Запуск

```bash
# Поднять стек в фоне
docker compose up -d

# Остановить
docker compose down

# Полностью удалить данные (векторы/модели/настройки)
rm -rf ./.data
```

### Открыть

- WebUI: <http://localhost:3000/>
- Qdrant: <http://localhost:6333/dashboard>

## Использование Open WebUI

- Админские данные задаются при первом заходе в open-webui

### Тестовые данные

- <https://zags.gov39.ru/docs/>

### Документация по RAG

- <https://docs.openwebui.com/features/rag>
- <https://docs.openwebui.com/troubleshooting/rag>

### Параметры поиска и RAG

- **Full Context Mode** — это режим, в котором модель получает для обработки сразу весь документ или всю коллекцию документов без предварительной нарезки на чанки и индексации через embeddings. В этом режиме нейросеть видит полный контекст объекта и может работать с ним как с цельным текстом, что особенно полезно при анализе небольших файлов или ситуациях, когда важна целостность информации. В Open-WebUI Full Context Mode выбирается через отдельный переключатель при загрузке файла или в настройках коллекции знаний.
- **Hybrid Search** — это комбинированный режим поиска, который объединяет традиционный векторный поиск по embeddings и полнотекстовый (keyword) поиск. Модель сначала находит релевантные фрагменты по смыслу (через embeddings и векторизацию RAG), а затем дополнительно использует ключевые слова для уточнения результата. Такой подход улучшает качество выдачи при сложных запросах или неидеальных embedding-моделях, позволяя учесть как смысловое соответствие, так и точное совпадение по словам.
- **Top K**: сколько релевантных документов будет учитываться для ответа, диапазон значений обычно 1-100.
- **Top K Reranker**: количество документов для переоценки. Обычно меньше чем Top K.
- **Chunk Size**: размер фрагмента при разбивке документа на части.
- **Chunk Overlap**: перекрытие токенов между кусками для лучшего поиска.
- **Text Splitter**: метод разбивки текста на части для индексации и поиска.
- **Embedding Model**: модель для преобразования текста в векторное представление.
- **Reranking Model**: модель для переоценки релевантности документов.
- **Datalab Marker**: настройки для аннотаций и разметки данных.
- **Relevance Threshold**: порог релевантности для фильтрации документов. Обычно выбирают значения в районе 0.5–0.7 (в зависимости от модели и типа данных)
- **Embedding Batch Size**: это число текстовых фрагментов или запросов, которые модель обрабатывает одновременно за один вызов API. Установите batch size от 16 до 64 для оптимального баланса между пропускной способностью и потреблением памяти.
