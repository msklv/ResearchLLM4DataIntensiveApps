# Корпоративный портал для поиска информации

## Технологии

- Ollama ([Сбер для теста](https://foundation-models.api.cloud.ru/v1))
- open-webui
- [Qdrant](https://qdrant.tech/)
- Docker

## Быстрый старт (docker-compose)

Для локального тестирования стека (Ollama + Qdrant + Open WebUI) используйте `docker-compose` ниже.

### Запуск

```bash
# Поднять стек в фоне
docker compose up -d

### Остановка и очистка

```bash
# Остановить контейнеры
docker compose down

# Полностью удалить данные (векторы/модели/настройки)
rm -rf ./.data
```

### Открыть

- Qdrant: <http://localhost:6333/dashboard>
- WebUI: <http://localhost:3000/>

## Использование Open WebUI

- Админские данные задаются при первом запуске

### Тестовые данные

- <https://zags.gov39.ru/docs/>

### Параметры поиска и RAG

- Top K: сколько релевантных документов будет учитываться для ответа, диапазон значений обычно 1-100.
- Top K Reranker: количество документов для переоценки. Обычно меньше чем Top K.
- Chunk Size: размер фрагмента при разбивке документа на части.
- Chunk Overlap: перекрытие токенов между кусками для лучшего поиска.
- Text Splitter: метод разбивки текста на части для индексации и поиска.
- Embedding Model: модель для преобразования текста в векторное представление.
- Reranking Model: модель для переоценки релевантности документов.
- Datalab Marker: настройки для аннотаций и разметки данных.
- **Full Context Mode** — это режим, в котором модель получает для обработки сразу весь документ или всю коллекцию документов без предварительной нарезки на чанки и индексации через embeddings. В этом режиме нейросеть видит полный контекст объекта и может работать с ним как с цельным текстом, что особенно полезно при анализе небольших файлов или ситуациях, когда важна целостность информации. В Open-WebUI Full Context Mode выбирается через отдельный переключатель при загрузке файла или в настройках коллекции знаний.
- **Hybrid Search** — это комбинированный режим поиска, который объединяет традиционный векторный поиск по embeddings и полнотекстовый (keyword) поиск. Модель сначала находит релевантные фрагменты по смыслу (через embeddings и векторизацию RAG), а затем дополнительно использует ключевые слова для уточнения результата. Такой подход улучшает качество выдачи при сложных запросах или неидеальных embedding-моделях, позволяя учесть как смысловое соответствие, так и точное совпадение по словам.

- Relevance Threshold: порог релевантности для фильтрации документов. Обычно выбирают значения в районе 0.5–0.7 (в зависимости от модели и типа данных)
